{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rzagni/itesm-aiml/blob/main/Deep%20Learning/A4_DL_TC5033_Transformer-2_Team56.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Advanced Machine Learning Methods**\n",
        "###**Tecnológico de Monterrey**\n",
        "###**Prof José Antonio Cantoral Ceballos**\n",
        "\n",
        "###**Word Embeddings**\n",
        "###**Activity 4: Implementing a Translator**\n",
        "\n",
        "#### **Team 56:**\n",
        "\n",
        "* Daniel Ruiz Gutiérrez A01100513\n",
        "* José Manuel GarcÍa Ogarrio A01795147\n",
        "* Miriam Bönsch A01330346\n",
        "* Raul Eduardo Gomez Godinez A01795214\n",
        "* Renzo Zagni A01795457\n",
        "* Roger Alexei Urrutia ParKer A01362405\n"
      ],
      "metadata": {
        "id": "F-ZZaM3QLYll"
      },
      "id": "F-ZZaM3QLYll"
    },
    {
      "cell_type": "markdown",
      "id": "41b7905f-a070-4ffe-abfc-67fbcd2adaa9",
      "metadata": {
        "id": "41b7905f-a070-4ffe-abfc-67fbcd2adaa9"
      },
      "source": [
        "## TC 5033\n",
        "## Deep Learning\n",
        "## Transformers\n",
        "\n",
        "#### Activity 4: Implementing a Translator\n",
        "\n",
        "- Objective\n",
        "\n",
        "To understand the Transformer Architecture by Implementing a translator.\n",
        "\n",
        "- Instructions\n",
        "\n",
        "    This activity requires submission in teams. While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
        "\n",
        "    Follow the provided code. The code already implements a transformer from scratch as explained in one of [week's 9 videos](https://youtu.be/XefFj4rLHgU)\n",
        "\n",
        "    Since the provided code already implements a simple translator, your job for this assignment is to understand it fully, and document it using pictures, figures, and markdown cells.  You should test your translator with at least 10 sentences. The dataset used for this task was obtained from [Tatoeba, a large dataset of sentences and translations](https://tatoeba.org/en/downloads).\n",
        "  \n",
        "- Evaluation Criteria\n",
        "\n",
        "    - Code Readability and Comments\n",
        "    - Traning a translator\n",
        "    - Translating at least 10 sentences.\n",
        "\n",
        "- Submission\n",
        "\n",
        "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f240f0d8-d9e0-4632-962f-1a5a7881cb5f",
      "metadata": {
        "id": "f240f0d8-d9e0-4632-962f-1a5a7881cb5f"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fHhwPJ6_LwmX",
        "outputId": "f88d58a3-4e6e-43b4-a893-c3b9acc88453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fHhwPJ6_LwmX",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5ebcf8f0-fcf0-4cf7-a549-0c68aa8eab1a",
      "metadata": {
        "id": "5ebcf8f0-fcf0-4cf7-a549-0c68aa8eab1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "17f54c65",
      "metadata": {
        "heading_collapsed": true,
        "id": "17f54c65"
      },
      "source": [
        "#### Script to convert csv to text file"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikbXdYHpLjui"
      },
      "id": "ikbXdYHpLjui",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8f02c0c2",
      "metadata": {
        "hidden": true,
        "id": "8f02c0c2"
      },
      "outputs": [],
      "source": [
        "#This script requires to convert the TSV file to CSV\n",
        "# easiest way is to open it in Calc or excel and save as csv\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/DL/A4/english-spanish.tsv'\n",
        "import pandas as pd\n",
        "df = pd.read_csv(PATH, sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "787d9408",
      "metadata": {
        "hidden": true,
        "id": "787d9408"
      },
      "outputs": [],
      "source": [
        "eng_spa_cols = df.iloc[:, [1, 3]]\n",
        "eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n",
        "eng_spa_cols = eng_spa_cols.sort_values(by='length')\n",
        "eng_spa_cols = eng_spa_cols.drop(columns=['length'])\n",
        "\n",
        "output_file_path = '/content/drive/MyDrive/Colab Notebooks/DL/A4/eng-spa4.txt'\n",
        "eng_spa_cols.to_csv(output_file_path, sep='\\t', index=False, header=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d468e9a",
      "metadata": {
        "id": "7d468e9a"
      },
      "source": [
        "## Transformer - Attention is all you need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d5dcf681",
      "metadata": {
        "id": "d5dcf681",
        "outputId": "64a99bd8-7601-4413-fcab-b74c0c77107a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a417fb40150>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "import math\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "torch.manual_seed(23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2c2cbd17",
      "metadata": {
        "id": "2c2cbd17",
        "outputId": "b3c662bb-1353-45ef-85c6-a4622592c49d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9c6623a1",
      "metadata": {
        "id": "9c6623a1"
      },
      "outputs": [],
      "source": [
        "MAX_SEQ_LEN = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3103d45f",
      "metadata": {
        "code_folding": [
          30,
          94
        ],
        "id": "3103d45f"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_len = MAX_SEQ_LEN):\n",
        "        super().__init__()\n",
        "        self.pos_embed_matrix = torch.zeros(max_seq_len, d_model, device=device)\n",
        "        token_pos = torch.arange(0, max_seq_len, dtype = torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n",
        "                             * (-math.log(10000.0)/d_model))\n",
        "        self.pos_embed_matrix[:, 0::2] = torch.sin(token_pos * div_term)\n",
        "        self.pos_embed_matrix[:, 1::2] = torch.cos(token_pos * div_term)\n",
        "        self.pos_embed_matrix = self.pos_embed_matrix.unsqueeze(0).transpose(0,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "#         print(self.pos_embed_matrix.shape)\n",
        "#         print(x.shape)\n",
        "        return x + self.pos_embed_matrix[:x.size(0), :]\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model = 512, num_heads = 8):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, 'Embedding size not compatible with num heads'\n",
        "\n",
        "        self.d_v = d_model // num_heads\n",
        "        self.d_k = self.d_v\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask = None):\n",
        "        batch_size = Q.size(0)\n",
        "        '''\n",
        "        Q, K, V -> [batch_size, seq_len, num_heads*d_k]\n",
        "        after transpose Q, K, V -> [batch_size, num_heads, seq_len, d_k]\n",
        "        '''\n",
        "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n",
        "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n",
        "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n",
        "\n",
        "        weighted_values, attention = self.scale_dot_product(Q, K, V, mask)\n",
        "        weighted_values = weighted_values.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads*self.d_k)\n",
        "        weighted_values = self.W_o(weighted_values)\n",
        "\n",
        "        return weighted_values, attention\n",
        "\n",
        "\n",
        "    def scale_dot_product(self, Q, K, V, mask = None):\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attention = F.softmax(scores, dim = -1)\n",
        "        weighted_values = torch.matmul(attention, V)\n",
        "\n",
        "        return weighted_values, attention\n",
        "\n",
        "\n",
        "class PositionFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(F.relu(self.linear1(x)))\n",
        "\n",
        "class EncoderSubLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = PositionFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.droupout1 = nn.Dropout(dropout)\n",
        "        self.droupout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask = None):\n",
        "        attention_score, _ = self.self_attn(x, x, x, mask)\n",
        "        x = x + self.droupout1(attention_score)\n",
        "        x = self.norm1(x)\n",
        "        x = x + self.droupout2(self.ffn(x))\n",
        "        return self.norm2(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([EncoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "    def forward(self, x, mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "class DecoderSubLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, target_mask=None, encoder_mask=None):\n",
        "        attention_score, _ = self.self_attn(x, x, x, target_mask)\n",
        "        x = x + self.dropout1(attention_score)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        encoder_attn, _ = self.cross_attn(x, encoder_output, encoder_output, encoder_mask)\n",
        "        x = x + self.dropout2(encoder_attn)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = x + self.dropout3(ff_output)\n",
        "        return self.norm3(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([DecoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, encoder_output, target_mask, encoder_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, target_mask, encoder_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "61070162",
      "metadata": {
        "code_folding": [],
        "id": "61070162"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers,\n",
        "                 input_vocab_size, target_vocab_size,\n",
        "                 max_len=MAX_SEQ_LEN, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_embedding = PositionalEmbedding(d_model, max_len)\n",
        "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
        "        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
        "        self.output_layer = nn.Linear(d_model, target_vocab_size)\n",
        "\n",
        "    def forward(self, source, target):\n",
        "        # Encoder mask\n",
        "        source_mask, target_mask = self.mask(source, target)\n",
        "        # Embedding and positional Encoding\n",
        "        source = self.encoder_embedding(source) * math.sqrt(self.encoder_embedding.embedding_dim)\n",
        "        source = self.pos_embedding(source)\n",
        "        # Encoder\n",
        "        encoder_output = self.encoder(source, source_mask)\n",
        "\n",
        "        # Decoder embedding and postional encoding\n",
        "        target = self.decoder_embedding(target) * math.sqrt(self.decoder_embedding.embedding_dim)\n",
        "        target = self.pos_embedding(target)\n",
        "        # Decoder\n",
        "        output = self.decoder(target, encoder_output, target_mask, source_mask)\n",
        "\n",
        "        return self.output_layer(output)\n",
        "\n",
        "\n",
        "\n",
        "    def mask(self, source, target):\n",
        "        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n",
        "        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n",
        "        size = target.size(1)\n",
        "        no_mask = torch.tril(torch.ones((1, size, size), device=device)).bool()\n",
        "        target_mask = target_mask & no_mask\n",
        "        return source_mask, target_mask\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da6b2d4",
      "metadata": {
        "heading_collapsed": true,
        "id": "6da6b2d4"
      },
      "source": [
        "#### Simple test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d40581d6",
      "metadata": {
        "hidden": true,
        "id": "d40581d6"
      },
      "outputs": [],
      "source": [
        "seq_len_source = 10\n",
        "seq_len_target = 10\n",
        "batch_size = 2\n",
        "input_vocab_size = 50\n",
        "target_vocab_size = 50\n",
        "\n",
        "source = torch.randint(1, input_vocab_size, (batch_size, seq_len_source))\n",
        "target = torch.randint(1, target_vocab_size, (batch_size, seq_len_target))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fc7cf689",
      "metadata": {
        "hidden": true,
        "id": "fc7cf689"
      },
      "outputs": [],
      "source": [
        "d_model = 512\n",
        "num_heads = 8\n",
        "d_ff = 2048\n",
        "num_layers = 6\n",
        "\n",
        "model = Transformer(d_model, num_heads, d_ff, num_layers,\n",
        "                  input_vocab_size, target_vocab_size,\n",
        "                  max_len=MAX_SEQ_LEN, dropout=0.1)\n",
        "\n",
        "model = model.to(device)\n",
        "source = source.to(device)\n",
        "target = target.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4618560e",
      "metadata": {
        "hidden": true,
        "id": "4618560e"
      },
      "outputs": [],
      "source": [
        "output = model(source, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ab0bc69d",
      "metadata": {
        "hidden": true,
        "id": "ab0bc69d",
        "outputId": "e5695430-4e57-4ec2-a9b9-81b479afb9e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ouput.shape torch.Size([2, 10, 50])\n"
          ]
        }
      ],
      "source": [
        "# Expected output shape -> [batch, seq_len_target, target_vocab_size] i.e. [2, 10, 50]\n",
        "print(f'ouput.shape {output.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4b2910",
      "metadata": {
        "id": "0f4b2910"
      },
      "source": [
        "### Translator Eng-Spa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "869a7244",
      "metadata": {
        "id": "869a7244"
      },
      "outputs": [],
      "source": [
        "#PATH = '/media/pepe/DataUbuntu/Databases/spanish_english/spa_eng/eng-spa.txt'\n",
        "PATH = output_file_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d0af1eba",
      "metadata": {
        "id": "d0af1eba"
      },
      "outputs": [],
      "source": [
        "with open(PATH, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "eng_spa_pairs = [line.strip().split('\\t') for line in lines if '\\t' in line]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c930226f",
      "metadata": {
        "id": "c930226f",
        "outputId": "df0a289f-acae-4216-fdc7-010c3ed1bee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Go.', 'Ve.'],\n",
              " ['Ow!', '¡Ay!'],\n",
              " ['So?', '¿Y qué?'],\n",
              " ['Go.', 'Váyase.'],\n",
              " ['OK.', '¡Órale!'],\n",
              " ['Go!', 'Vete'],\n",
              " ['Hi.', '¡Hola!'],\n",
              " ['Go!', 'Váyase'],\n",
              " ['Go!', '¡Fuera!'],\n",
              " ['So?', '¿Y?']]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "eng_spa_pairs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "095f4037",
      "metadata": {
        "id": "095f4037"
      },
      "outputs": [],
      "source": [
        "eng_sentences = [pair[0] for pair in eng_spa_pairs]\n",
        "spa_sentences = [pair[1] for pair in eng_spa_pairs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "0d9e1c95",
      "metadata": {
        "id": "0d9e1c95",
        "outputId": "394d5f0e-69bc-449b-96f8-0545b0dd3b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Go.', 'Ow!', 'So?', 'Go.', 'OK.', 'Go!', 'Hi.', 'Go!', 'Go!', 'So?']\n",
            "['Ve.', '¡Ay!', '¿Y qué?', 'Váyase.', '¡Órale!', 'Vete', '¡Hola!', 'Váyase', '¡Fuera!', '¿Y?']\n"
          ]
        }
      ],
      "source": [
        "print(eng_sentences[:10])\n",
        "print(spa_sentences[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "60d11478",
      "metadata": {
        "id": "60d11478"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n",
        "    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n",
        "    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n",
        "    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n",
        "    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n",
        "    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "    sentence = '<sos> ' + sentence + ' <eos>'\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "478f673b",
      "metadata": {
        "id": "478f673b"
      },
      "outputs": [],
      "source": [
        "s1 = '¿Hola @ cómo estás? 123'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "96ac79c5",
      "metadata": {
        "id": "96ac79c5",
        "outputId": "41b48c64-eafb-48e8-dfdf-ae61bf71eb2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¿Hola @ cómo estás? 123\n",
            "<sos> hola como estas <eos>\n"
          ]
        }
      ],
      "source": [
        "print(s1)\n",
        "print(preprocess_sentence(s1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d9fc9c4d",
      "metadata": {
        "id": "d9fc9c4d"
      },
      "outputs": [],
      "source": [
        "eng_sentences = [preprocess_sentence(sentence) for sentence in eng_sentences]\n",
        "spa_sentences = [preprocess_sentence(sentence) for sentence in spa_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "f7a3b18d",
      "metadata": {
        "id": "f7a3b18d",
        "outputId": "2d1a6b76-e19e-42d0-be3d-8ad4ba41357c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos> ve <eos>',\n",
              " '<sos> ay <eos>',\n",
              " '<sos> y que <eos>',\n",
              " '<sos> vayase <eos>',\n",
              " '<sos> orale <eos>',\n",
              " '<sos> vete <eos>',\n",
              " '<sos> hola <eos>',\n",
              " '<sos> vayase <eos>',\n",
              " '<sos> fuera <eos>',\n",
              " '<sos> y <eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "spa_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "97931cd3",
      "metadata": {
        "id": "97931cd3"
      },
      "outputs": [],
      "source": [
        "def build_vocab(sentences):\n",
        "    words = [word for sentence in sentences for word in sentence.split()]\n",
        "    word_count = Counter(words)\n",
        "    sorted_word_counts = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
        "    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n",
        "    word2idx['<pad>'] = 0\n",
        "    word2idx['<unk>'] = 1\n",
        "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "    return word2idx, idx2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "7fa8738e",
      "metadata": {
        "id": "7fa8738e"
      },
      "outputs": [],
      "source": [
        "eng_word2idx, eng_idx2word = build_vocab(eng_sentences)\n",
        "spa_word2idx, spa_idx2word = build_vocab(spa_sentences)\n",
        "eng_vocab_size = len(eng_word2idx)\n",
        "spa_vocab_size = len(spa_word2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "79d6b633",
      "metadata": {
        "id": "79d6b633",
        "outputId": "3eabbe2e-72e9-466f-a72a-81aa9aaf6676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27650 46929\n"
          ]
        }
      ],
      "source": [
        "print(eng_vocab_size, spa_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "e564017c",
      "metadata": {
        "id": "e564017c"
      },
      "outputs": [],
      "source": [
        "class EngSpaDataset(Dataset):\n",
        "    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n",
        "        self.eng_sentences = eng_sentences\n",
        "        self.spa_sentences = spa_sentences\n",
        "        self.eng_word2idx = eng_word2idx\n",
        "        self.spa_word2idx = spa_word2idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.eng_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        eng_sentence = self.eng_sentences[idx]\n",
        "        spa_sentence = self.spa_sentences[idx]\n",
        "        # return tokens idxs\n",
        "        eng_idxs = [self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n",
        "        spa_idxs = [self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n",
        "\n",
        "        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "b579577b",
      "metadata": {
        "id": "b579577b"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    eng_batch, spa_batch = zip(*batch)\n",
        "    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n",
        "    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n",
        "    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n",
        "    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n",
        "    return eng_batch, spa_batch\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "8d514b7c",
      "metadata": {
        "id": "8d514b7c"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, loss_function, optimiser, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n",
        "            eng_batch = eng_batch.to(device)\n",
        "            spa_batch = spa_batch.to(device)\n",
        "            # Decoder preprocessing\n",
        "            target_input = spa_batch[:, :-1]\n",
        "            target_output = spa_batch[:, 1:].contiguous().view(-1)\n",
        "            # Zero grads\n",
        "            optimiser.zero_grad()\n",
        "            # run model\n",
        "            output = model(eng_batch, target_input)\n",
        "            output = output.view(-1, output.size(-1))\n",
        "            # loss\\\n",
        "            loss = loss_function(output, target_output)\n",
        "            # gradient and update parameters\n",
        "            loss.backward()\n",
        "            optimiser.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss/len(dataloader)\n",
        "        print(f'Epoch: {epoch}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "2379ea72",
      "metadata": {
        "id": "2379ea72"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "dataset = EngSpaDataset(eng_sentences, spa_sentences, eng_word2idx, spa_word2idx)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "e08eef6a",
      "metadata": {
        "id": "e08eef6a"
      },
      "outputs": [],
      "source": [
        "model = Transformer(d_model=512, num_heads=8, d_ff=2048, num_layers=6,\n",
        "                    input_vocab_size=eng_vocab_size, target_vocab_size=spa_vocab_size,\n",
        "                    max_len=MAX_SEQ_LEN, dropout=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "a1181a12",
      "metadata": {
        "id": "a1181a12"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimiser = optim.Adam(model.parameters(), lr=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e265e9",
      "metadata": {
        "id": "14e265e9"
      },
      "outputs": [],
      "source": [
        "train(model, dataloader, loss_function, optimiser, epochs = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d271146",
      "metadata": {
        "id": "1d271146"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50740746",
      "metadata": {
        "code_folding": [],
        "id": "50740746"
      },
      "outputs": [],
      "source": [
        "def sentence_to_indices(sentence, word2idx):\n",
        "    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n",
        "\n",
        "def indices_to_sentence(indices, idx2word):\n",
        "    return ' '.join([idx2word[idx] for idx in indices if idx in idx2word and idx2word[idx] != '<pad>'])\n",
        "\n",
        "def translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
        "    model.eval()\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    input_indices = sentence_to_indices(sentence, eng_word2idx)\n",
        "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    # Initialize the target tensor with <sos> token\n",
        "    tgt_indices = [spa_word2idx['<sos>']]\n",
        "    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            output = model(input_tensor, tgt_tensor)\n",
        "            output = output.squeeze(0)\n",
        "            next_token = output.argmax(dim=-1)[-1].item()\n",
        "            tgt_indices.append(next_token)\n",
        "            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
        "            if next_token == spa_word2idx['<eos>']:\n",
        "                break\n",
        "\n",
        "    return indices_to_sentence(tgt_indices, spa_idx2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c0db72",
      "metadata": {
        "code_folding": [
          15
        ],
        "id": "c2c0db72"
      },
      "outputs": [],
      "source": [
        "def evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
        "    for sentence in sentences:\n",
        "        translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n",
        "        print(f'Input sentence: {sentence}')\n",
        "        print(f'Traducción: {translation}')\n",
        "        print()\n",
        "\n",
        "# Example sentences to test the translator\n",
        "test_sentences = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"I am learning artificial intelligence.\",\n",
        "    \"Artificial intelligence is great.\",\n",
        "    \"Good night!\"\n",
        "]\n",
        "\n",
        "# Assuming the model is trained and loaded\n",
        "# Set the device to 'cpu' or 'cuda' as needed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Evaluate translations\n",
        "evaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ceefe95",
      "metadata": {
        "id": "4ceefe95"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7e10a50",
      "metadata": {
        "id": "a7e10a50"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bffb7af9",
      "metadata": {
        "id": "bffb7af9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6321db74",
      "metadata": {
        "id": "6321db74"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccce7864",
      "metadata": {
        "id": "ccce7864"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}